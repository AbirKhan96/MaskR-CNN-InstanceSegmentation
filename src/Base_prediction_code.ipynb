{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "established-airplane",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 16:53:40.161 | DEBUG    | pipeline.utils.file.save:dump:6 - saved ['store/model/Allowed_Classes/dta_cfg.bin']\n",
      "2021-05-13 16:53:40.162 | DEBUG    | pipeline.utils.file.save:dump:6 - saved ['store/model/Allowed_Classes/mdl_cfg.bin']\n",
      "2021-05-13 16:53:40.163 | DEBUG    | pipeline.utils.file.save:dump:6 - saved ['store/model/Allowed_Classes/trn_cfg.bin']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================================================================================================\n",
      "learning param base_lr            : 0.00025\n",
      "learning param max_iter           : 10000\n",
      "learning param batch_size_per_im  : 256\n",
      "learning param ims_per_batch      : 16\n",
      "learning param num_workers        : 25\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# cleaned using `utils/checknames.py`\n",
    "from pipeline.train.det2.trainer import Det2Trainer\n",
    "from config import TrainConfig, DataConfig, ModelConfig, DataPreparationConfig\n",
    "import os, json, io, base64, cv2, glob\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import labelme\n",
    "# # configure trainer\n",
    "# trainer = Det2Trainer(\n",
    "#   data=DataConfig.POC102Assets_JsonDataset,\n",
    "#   model=ModelConfig.POC102Assets_JsonModel,\n",
    "#   cfg=TrainConfig)\n",
    "\n",
    "# configure trainer\n",
    "trainer = Det2Trainer(\n",
    "  data=DataConfig.AllowedClassesDataset,\n",
    "  model=ModelConfig.Allowed_ClassesModel,\n",
    "  cfg=TrainConfig)\n",
    "THING_CLASSES = DataConfig.AllowedClassesDataset.thing_classes\n",
    "\n",
    "# removed the classes that exist in holdout / test but not in train. Need to implement sampler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebeba9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loguru\n",
      "  Using cached loguru-0.5.3-py3-none-any.whl (57 kB)\n",
      "Collecting aiocontextvars>=0.2.0\n",
      "  Using cached aiocontextvars-0.2.2-py2.py3-none-any.whl (4.9 kB)\n",
      "Collecting contextvars==2.4\n",
      "  Using cached contextvars-2.4-py3-none-any.whl\n",
      "Collecting immutables>=0.9\n",
      "  Using cached immutables-0.15-cp36-cp36m-manylinux1_x86_64.whl (100 kB)\n",
      "Installing collected packages: immutables, contextvars, aiocontextvars, loguru\n",
      "Successfully installed aiocontextvars-0.2.2 contextvars-2.4 immutables-0.15 loguru-0.5.3\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.0.1\n",
      "Collecting labelme\n",
      "  Using cached labelme-4.5.7-py3-none-any.whl\n",
      "Collecting matplotlib<3.3\n",
      "  Using cached matplotlib-3.2.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "Requirement already satisfied: qtpy in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from labelme) (1.9.0)\n",
      "Requirement already satisfied: termcolor in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from labelme) (1.1.0)\n",
      "Collecting PyQt5\n",
      "  Using cached PyQt5-5.15.4-cp36.cp37.cp38.cp39-abi3-manylinux2014_x86_64.whl (8.3 MB)\n",
      "Requirement already satisfied: PyYAML in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from labelme) (5.4.1)\n",
      "Requirement already satisfied: Pillow>=2.8.0 in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from labelme) (8.2.0)\n",
      "Collecting imgviz>=0.11.0\n",
      "  Using cached imgviz-1.2.6-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from labelme) (1.19.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from matplotlib<3.3->labelme) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from matplotlib<3.3->labelme) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from matplotlib<3.3->labelme) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from matplotlib<3.3->labelme) (1.3.1)\n",
      "Requirement already satisfied: six in /home/itis/Desktop/Delivery_jaipur/myenv/lib/python3.6/site-packages (from cycler>=0.10->matplotlib<3.3->labelme) (1.16.0)\n",
      "Collecting PyQt5-Qt5>=5.15\n",
      "  Using cached PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
      "Collecting PyQt5-sip<13,>=12.8\n",
      "  Using cached PyQt5_sip-12.8.1-cp36-cp36m-manylinux1_x86_64.whl (278 kB)\n",
      "Installing collected packages: PyQt5-sip, PyQt5-Qt5, matplotlib, PyQt5, imgviz, labelme\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.3.4\n",
      "    Uninstalling matplotlib-3.3.4:\n",
      "      Successfully uninstalled matplotlib-3.3.4\n",
      "Successfully installed PyQt5-5.15.4 PyQt5-Qt5-5.15.2 PyQt5-sip-12.8.1 imgviz-1.2.6 labelme-4.5.7 matplotlib-3.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install loguru\n",
    "!pip install joblib\n",
    "!pip install labelme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-horror",
   "metadata": {},
   "source": [
    "# Run Visualisations on ANY Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greater-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy\n",
    "import copy\n",
    "from loguru import logger\n",
    "\n",
    "def dump(obj, saveby='./temp.bin'):\n",
    "    ret = joblib.dump(obj, saveby)\n",
    "    logger.debug(f\"saved {ret}\")\n",
    "\n",
    "def load(from_path):\n",
    "    return joblib.load(from_path)\n",
    "def load_bin(from_path):\n",
    "    return joblib.load(from_path)\n",
    "\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "metadata = MetadataCatalog.get(\"dataset_train\")\n",
    "def get_seg_dict(predictor, on_im, save_dir, fname, THING_CLASSES):\n",
    "    \n",
    "\n",
    "    im = cv2.imread(on_im)\n",
    "    # format at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    # print(len(outputs.keys())) #--> 1\n",
    "    dic = outputs['instances'].__dict__\n",
    "    \n",
    "    pred_class_list =list(dic['_fields']['pred_classes'].cpu().numpy())\n",
    "    print (pred_class_list)\n",
    "    del dic['_fields']['pred_classes']\n",
    "    dic['_fields']['pred_classes'] = []\n",
    "    for obj in pred_class_list:\n",
    "        dic['_fields']['pred_classes'].append(THING_CLASSES[obj])\n",
    "        \n",
    "    dic['_fields']['pred_classes'] = numpy.array(dic['_fields']['pred_classes'])\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "            metadata=metadata, \n",
    "            scale=0.5, \n",
    "            instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    #plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    #plt.show()\n",
    "    #plt.close()\n",
    "    \n",
    "    ## To save image please un comment below line.\n",
    "    dic['_fields']['pred_classes']\n",
    "    img = cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(save_dir+'/'+fname, img)\n",
    "    \n",
    "    #print(dic['_image_size']) #--> (4608, 9216)\n",
    "    \n",
    "    # print(dic['_fields'].keys()) #--> ['pred_boxes', 'scores', 'pred_classes', 'pred_masks']\n",
    "    \n",
    "    # print(dic['_fields']['pred_boxes'].tensor.cpu().detach().numpy())\n",
    "    \n",
    "\n",
    "\n",
    "    dic = {\n",
    "        'imgShape': dic['_image_size'],\n",
    "        'predClasses': dic['_fields']['pred_classes'],\n",
    "        'predBoxes': dic['_fields']['pred_boxes'].tensor.cpu().detach().numpy(),\n",
    "        'boxScores': dic['_fields']['scores'].cpu().detach().numpy()\n",
    "    }\n",
    "    return dic\n",
    "\n",
    "\n",
    "\n",
    "def get_im_seg_info(images_dir, predictor, save_dir, THING_CLASSES, ext='jpg'):\n",
    "    \n",
    "    #  vis_metadata = load_bin(from_path=vis_metadata)  # train metadata\n",
    "\n",
    "    write_dir = save_dir + f\"eval_{images_dir[:-1].split('/')[-1]}\" + '/'\n",
    "    logger.debug(f\"saving segmented images in {write_dir}\")\n",
    "    os.makedirs(write_dir, exist_ok=True)\n",
    "\n",
    "    # check..\n",
    "    # logger.debug(vis_metadata.thing_classes)\n",
    "\n",
    "    #list_of_dics = []\n",
    "    for im_name in os.listdir(images_dir):\n",
    "        if im_name.split('.')[-1].lower() == ext.lower():\n",
    "            \n",
    "            dic = get_seg_dict(\n",
    "                predictor=predictor,\n",
    "                on_im=images_dir+im_name,\n",
    "                save_dir = save_dir,\n",
    "                fname= im_name,\n",
    "                THING_CLASSES=THING_CLASSES\n",
    "            )\n",
    "            \n",
    "            #from pprint import pprint\n",
    "            #pprint(dic_str)\n",
    "            dic['imageName'] = im_name\n",
    "            \n",
    "            \n",
    "            joblib.dump((copy.deepcopy(dic), THING_CLASSES), write_dir + f'{im_name}.segmentation_info.bin')\n",
    "            \n",
    "            #list_of_dics.append(dic)\n",
    "\n",
    "    return None   \n",
    "\n",
    "\n",
    "THING_CLASSES = DataConfig.AllowedClassesDataset.thing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "retained-hardwood",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[1m\u001b[37mINFO   \u001b[0m] \u001b[36mcheckpoint\u001b[0m:\u001b[36mload\u001b[0m:\u001b[36m138\u001b[0m - \u001b[1m\u001b[37m[Checkpointer] Loading from store/model/Allowed_Classes/model_final.pth ...\u001b[0m\n",
      "2021-05-13 16:54:50.637 | DEBUG    | __main__:get_im_seg_info:77 - saving segmented images in store/data/Allowed_Classes/prediction/eval_test/\n",
      "/home/itis/Desktop/flag1/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:154: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  filter_inds = filter_mask.nonzero()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[0]\n",
      "[0]\n",
      "[]\n",
      "[0]\n",
      "[]\n",
      "[0, 0]\n",
      "[0]\n",
      "[]\n",
      "[]\n",
      "[0]\n",
      "[0]\n",
      "[0, 0]\n",
      "[0]\n",
      "[0]\n",
      "[0, 0]\n",
      "[0]\n",
      "[0]\n",
      "[0, 0]\n",
      "[0]\n",
      "[0, 0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0, 0, 0]\n",
      "[0]\n",
      "[0]\n",
      "[0, 0]\n",
      "[0, 0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from pipeline.eval.det2.get_model import GetTrained\n",
    "\n",
    "predictor, cfg = (\n",
    "        GetTrained(ModelConfig.Allowed_ClassesModel.__name__.replace(\"Model\", \"\"))\n",
    "        .fetch(thresh=0.5, cfg=True))\n",
    "get_im_seg_info(\"/home/itis/Desktop/flag1/src/store/data/Allowed_Classes/test/\", predictor, \"store/data/Allowed_Classes/prediction/\", THING_CLASSES, ext='jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "auburn-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(THING_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-frederick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
